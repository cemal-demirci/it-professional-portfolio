import { GoogleGenerativeAI } from '@google/generative-ai'
import storage from '../utils/storage'

const API_KEY = import.meta.env.VITE_GEMINI_API_KEY

// Rate limiting - Server-side API with Vercel KV (works in incognito mode!)
const RATE_LIMIT = 15 // requests per day for free tier
const RATE_WINDOW = 86400000 // 24 hours in ms
const API_BASE = import.meta.env.VITE_API_BASE || ''

// Secret key for unlimited access
const SECRET_KEY = 'unlimited2024'

// Check if unlimited mode is enabled
const isUnlimitedMode = () => {
  const storedKey = localStorage.getItem('aiUnlimitedKey')
  return storedKey === SECRET_KEY
}

// Get unlimited key for API header
const getUnlimitedKey = () => {
  return isUnlimitedMode() ? SECRET_KEY : null
}

// Get current rate limit based on mode
const getCurrentRateLimit = () => {
  return isUnlimitedMode() ? 999999 : RATE_LIMIT
}

// Character limits
export const LIMITS = {
  MAX_INPUT_CHARS: 30000, // 30K characters per request
  MAX_OUTPUT_TOKENS: 2048,
  RATE_LIMIT: RATE_LIMIT,
  RATE_WINDOW_HOURS: RATE_WINDOW / 3600000 // 24 hours
}

let genAI = null

export const initGemini = () => {
  if (!API_KEY || API_KEY === 'your_api_key_here') {
    throw new Error('Gemini API key not configured. Please add VITE_GEMINI_API_KEY to .env file')
  }

  if (!genAI) {
    genAI = new GoogleGenerativeAI(API_KEY)
  }

  return genAI
}

// Sarcastic messages - Cemal style (TR/EN mix)
const SARCASTIC_MESSAGES = {
  rateLimitReached: (waitTime, limit) => {
    const hours = Math.floor(waitTime / 3600)
    const minutes = Math.floor((waitTime % 3600) / 60)
    const timeStr = hours > 0 ? `${hours}h ${minutes}m` : `${minutes}m`

    return [
      `YavaÅŸ kardeÅŸim! ðŸ¢ GÃ¼nlÃ¼k limit: ${limit}/day. ${timeStr} bekle, acele etme!`,
      `Whoa there, cowboy! ðŸ¤  Daily limit: ${limit}. Come back in ${timeStr} â˜•`,
      `Easy tiger! ðŸ… AI'Ä±n da dinlenmesi lazÄ±m. Wait ${timeStr} bro.`,
      `Sakin! ðŸŽï¸ Free tier = ${limit}/gÃ¼n. Chill yap ${timeStr}.`,
      `Houston, we have a problem! ðŸš€ GÃ¼nlÃ¼k ${limit} limit aÅŸtÄ±n. ${timeStr} sonra gel.`,
      `Slow down amigo! âš¡ ${limit} request/day limit var. ${timeStr} bekle.`
    ]
  },
  inputTooLong: (current, max) => [
    `Sen romana mÄ± yazÄ±yorsun? ðŸ“š ${current.toLocaleString()} karakter var, max ${max.toLocaleString()}. KÄ±sa tut!`,
    `That's a novel, not a query! ðŸ“– ${current.toLocaleString()}/${max.toLocaleString()} chars. TLDR lÃ¼tfen!`,
    `Ã‡ok uzun yazmÄ±ÅŸsÄ±n aga! âœï¸ ${current.toLocaleString()} chars ama max ${max.toLocaleString()}. Edit et!`,
    `War and Peace mi yazÄ±yorsun? ðŸ“• Current: ${current.toLocaleString()}, Max: ${max.toLocaleString()}. Trim yap!`,
    `Essay deÄŸil query istiyorum! ðŸ“ ${current.toLocaleString()}/${max.toLocaleString()} - Summarize et bro!`
  ],
  apiKeyInvalid: () => [
    `API key Ã§alÄ±ÅŸmÄ±yor sanki ðŸ™… Google AI Studio'da check et!`,
    `Bu API key sahte gibi ðŸ’¸ .env file'Ä± kontrol et!`,
    `API key rejected! ðŸ˜… Typo mu var acaba? Verify et!`,
    `Key geÃ§ersiz kardeÅŸim ðŸ”‘ Double-check yap bakalÄ±m!`,
    `Nope! ðŸš« That API key ain't working. DoÄŸru yazdÄ±n mÄ±?`
  ],
  quotaExceeded: () => [
    `Google "yeter artÄ±k" dedi ðŸ›‘ Quota aÅŸtÄ±n. Biraz bekle!`,
    `Quota bitti! ðŸ“Š Free tier'Ä±n da limiti var. Try again later.`,
    `You've used up Google's patience ðŸ˜¬ Ve quota'yÄ± da. Bekle biraz!`,
    `Limit doldu kardeÅŸim! ðŸŽ¯ Free tier bu kadar. Snack break?`,
    `Resource exhausted! ðŸ’¤ Google needs a break too. Wait a bit bro.`
  ],
  success: (time) => [
    `Boom! ðŸ’¥ ${time}s'de hallettim. I'm basically magic âœ¨`,
    `Bitti bile! âš¡ ${time}s'de done. You're welcome ðŸ˜Ž`,
    `${time}s'de analysis complete ðŸŽ¯ Check et aÅŸaÄŸÄ±da!`,
    `Ez pz! ðŸš€ ${time} saniyede bitti. That AI wisdom tho ðŸ§ `,
    `Done in ${time}s! ðŸ’ª Masterpiece gibi oldu.`
  ],
  approachingLimit: () => [
    `Getting chunky! ðŸ“ Limite yaklaÅŸÄ±yorsun. Maybe summarize?`,
    `Dikkat! âš ï¸ You're near the max. KÄ±sa tut biraz!`,
    `Careful there, wordsmith! âœï¸ Limit yakÄ±n. Keep it concise!`,
    `Uzuyor ha! ðŸ“ Character limit yaklaÅŸÄ±yor. TLDR yap!`
  ],
  analyzing: () => [
    `AI dÃ¼ÅŸÃ¼nÃ¼yor... ðŸ¤” SabÄ±r!`,
    `Processing... âš™ï¸ Magic takes time!`,
    `Analyzing yapÄ±yorum... ðŸ§  Wait for it!`,
    `Thinking... ðŸ’­ Almost there bro!`
  ],
  noInput: () => [
    `BoÅŸ mu gÃ¶nderiyorsun? ðŸ¤¨ Write something first!`,
    `Bi ÅŸeyler yaz Ã¶nce! âœï¸ Input lazÄ±m!`,
    `Empty input detected! ðŸ“­ Type something!`
  ]
}

const getRandomMessage = (messageArrayOrFunc) => {
  const messages = typeof messageArrayOrFunc === 'function' ? messageArrayOrFunc : messageArrayOrFunc
  return Array.isArray(messages) ? messages[Math.floor(Math.random() * messages.length)] : messages
}

// Check rate limit - Server-side API with Vercel KV (with localStorage fallback for dev)
export const checkRateLimit = async () => {
  try {
    const headers = {}
    const unlimitedKey = getUnlimitedKey()
    if (unlimitedKey) {
      headers['x-unlimited-key'] = unlimitedKey
    }

    const response = await fetch(`${API_BASE}/api/ratelimit`, {
      method: 'GET',
      headers
    })

    const data = await response.json()

    if (!response.ok || !data.success) {
      throw new Error(data.error || 'Rate limit check failed')
    }

    if (data.remaining <= 0) {
      const currentLimit = data.limit
      const waitTimeSeconds = data.waitTimeSeconds || 3600
      const messages = SARCASTIC_MESSAGES.rateLimitReached(waitTimeSeconds, currentLimit)
      throw new Error(getRandomMessage(messages))
    }

    return true
  } catch (error) {
    // Fallback to localStorage-based rate limiting for development
    console.warn('Server API unavailable, using localStorage fallback:', error.message)
    return checkRateLimitLocal()
  }
}

// Local rate limiting fallback (for development)
const checkRateLimitLocal = () => {
  if (isUnlimitedMode()) {
    return true
  }

  const storageKey = 'local_rate_limit'
  const now = Date.now()

  // Get existing requests
  const data = localStorage.getItem(storageKey)
  const requests = data ? JSON.parse(data) : []

  // Filter recent requests (within 24 hours)
  const recentRequests = requests.filter(time => now - time < RATE_WINDOW)

  // Check if limit exceeded
  if (recentRequests.length >= RATE_LIMIT) {
    const oldestRequest = recentRequests[0]
    const waitTimeSeconds = Math.ceil((RATE_WINDOW - (now - oldestRequest)) / 1000)
    const messages = SARCASTIC_MESSAGES.rateLimitReached(waitTimeSeconds, RATE_LIMIT)
    throw new Error(getRandomMessage(messages))
  }

  return true
}

// Record request - Server-side API with Vercel KV (with localStorage fallback for dev)
const recordRequest = async () => {
  try {
    const headers = {}
    const unlimitedKey = getUnlimitedKey()
    if (unlimitedKey) {
      headers['x-unlimited-key'] = unlimitedKey
    }

    const response = await fetch(`${API_BASE}/api/ratelimit`, {
      method: 'POST',
      headers
    })

    const data = await response.json()

    if (response.status === 429) {
      // Rate limit exceeded after request was made
      // This shouldn't happen if checkRateLimit works correctly
      console.warn('Rate limit exceeded during recording')
    }

    return data.success
  } catch (error) {
    console.warn('Failed to record request, using localStorage fallback:', error.message)
    recordRequestLocal()
    return false
  }
}

// Local request recording fallback (for development)
const recordRequestLocal = () => {
  if (isUnlimitedMode()) {
    return
  }

  const storageKey = 'local_rate_limit'
  const now = Date.now()

  // Get existing requests
  const data = localStorage.getItem(storageKey)
  const requests = data ? JSON.parse(data) : []

  // Add new request
  requests.push(now)

  // Filter recent requests and save
  const recentRequests = requests.filter(time => now - time < RATE_WINDOW)
  localStorage.setItem(storageKey, JSON.stringify(recentRequests))
}

// Get remaining requests - Server-side API with Vercel KV (with localStorage fallback for dev)
export const getRemainingRequests = async () => {
  try {
    const headers = {}
    const unlimitedKey = getUnlimitedKey()
    if (unlimitedKey) {
      headers['x-unlimited-key'] = unlimitedKey
    }

    const response = await fetch(`${API_BASE}/api/ratelimit`, {
      method: 'GET',
      headers
    })

    const data = await response.json()

    if (response.ok && data.success) {
      return data.remaining
    }

    // Fallback
    return getCurrentRateLimit()
  } catch (error) {
    console.warn('Failed to get remaining requests, using localStorage fallback')
    return getRemainingRequestsLocal()
  }
}

// Local remaining requests (for development)
const getRemainingRequestsLocal = () => {
  if (isUnlimitedMode()) {
    return 999999
  }

  const storageKey = 'local_rate_limit'
  const now = Date.now()

  // Get existing requests
  const data = localStorage.getItem(storageKey)
  const requests = data ? JSON.parse(data) : []

  // Filter recent requests
  const recentRequests = requests.filter(time => now - time < RATE_WINDOW)

  return Math.max(0, RATE_LIMIT - recentRequests.length)
}

export const analyzeWithGemini = async (prompt, systemInstruction = '', options = {}) => {
  try {
    // Check input length
    const totalInput = systemInstruction + prompt
    if (totalInput.length > LIMITS.MAX_INPUT_CHARS) {
      throw new Error(getRandomMessage(SARCASTIC_MESSAGES.inputTooLong(totalInput.length, LIMITS.MAX_INPUT_CHARS)))
    }

    // Check rate limit (IP-based)
    if (!options.bypassRateLimit) {
      await checkRateLimit()
    }

    const ai = initGemini()
    const model = ai.getGenerativeModel({
      model: 'gemini-2.0-flash-exp', // Latest fast model
      generationConfig: {
        temperature: 0.7,
        topK: 40,
        topP: 0.95,
        maxOutputTokens: LIMITS.MAX_OUTPUT_TOKENS,
      },
      systemInstruction: systemInstruction || undefined
    })

    const result = await model.generateContent(prompt)
    const response = await result.response

    // Record successful request (IP-based)
    if (!options.bypassRateLimit) {
      await recordRequest()
    }

    return response.text()
  } catch (error) {
    if (error.message.includes('API key') && !error.message.includes('nope')) {
      throw new Error(getRandomMessage(SARCASTIC_MESSAGES.apiKeyInvalid()))
    }
    if (error.message.includes('PERMISSION_DENIED')) {
      throw new Error(getRandomMessage(SARCASTIC_MESSAGES.apiKeyInvalid()))
    }
    if (error.message.includes('RESOURCE_EXHAUSTED')) {
      throw new Error(getRandomMessage(SARCASTIC_MESSAGES.quotaExceeded()))
    }
    throw error
  }
}

// Export sarcastic messages for use in components
export { SARCASTIC_MESSAGES, getRandomMessage }

export const streamAnalyzeWithGemini = async (prompt, systemInstruction = '', onChunk) => {
  try {
    // Check input length
    const totalInput = systemInstruction + prompt
    if (totalInput.length > LIMITS.MAX_INPUT_CHARS) {
      throw new Error(`Input too long. Maximum ${LIMITS.MAX_INPUT_CHARS.toLocaleString()} characters allowed.`)
    }

    // Check rate limit (IP-based)
    await checkRateLimit()

    const ai = initGemini()
    const model = ai.getGenerativeModel({
      model: 'gemini-2.0-flash-exp',
      systemInstruction: systemInstruction || undefined
    })

    const result = await model.generateContentStream(prompt)

    // Record request (IP-based)
    await recordRequest()

    let fullText = ''
    for await (const chunk of result.stream) {
      const chunkText = chunk.text()
      fullText += chunkText
      if (onChunk) {
        onChunk(chunkText, fullText)
      }
    }

    return fullText
  } catch (error) {
    throw error
  }
}
